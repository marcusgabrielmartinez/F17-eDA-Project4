---
title: "Prediction of Parkinson's Disease"
author: 'Group 2: Kelly Jennings, Stefanos Kapetanakis, Marcus Martinez, Rachel Tarrant, Changyong Yi'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
require(dplyr)
require(MASS)
require(ISLR)
require(ggplot2)
library(leaps)
library(glmnet)
require(tree)
require(randomForest)
require(gbm)
require(data.world)
require(shiny)
require(e1071)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
https://github.com/marcusgabrielmartinez/F17-eDA-Project4

## **Data.World Link**
https://data.world/tarrantrl/f-17-eda-project-4

## **Connecting to data.world** 
```{r}
project <- "https://data.world/tarrantrl/parkinsons-telemonitoring"
data.world::set_config(cfg_env("DW_API"))
df <- data.world::query(
  data.world::qry_sql("SELECT * FROM parkinsons_telemonitoring"),
  dataset = project
)
```

## Setup
We created several dataframes for our analyses. We created a binary version of the sex variable as well as a classification version of age (dividing into less than or equal to 65 and older than 65). We also removed subject from the dataframes we used for modeling because it is simily and id number. For predicting total updrs, we removed motor updrs because these are just different measurements of the same outcome variable; therefore, motor updrs is not a meaningful predictor of total updrs. We also created a training sample with indeces for half of the rows in the data.
```{r}
attach(df)

df_age <- df %>% dplyr::select(., -subject) %>% dplyr::mutate(age2 = ifelse(age <= 65, 1, 0)) %>% dplyr::mutate(sex = as.factor(sex))

df_sex <- df %>% dplyr::select(., -subject) %>% dplyr::mutate(sex2 = ifelse(sex == "true", 1, 0)) %>% dplyr::mutate(age = as.factor(age))

df_tot_nums = df %>% dplyr::mutate(sex2 = ifelse(sex == "true", 1, 0)) %>% dplyr::select(-sex,-subject,-motor_updrs)

df2 = dplyr::select(df, -subject)
df2 <- df2 %>% dplyr::mutate(sex2 = ifelse(sex == "true", 1, 0))
df2 = dplyr::select(df2, -sex)

train=sample(1:nrow(df_tot_nums),2937)
```
## **Introduction** 

"This dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.

Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures."


subject# - Integer that uniquely identifies each subject 
age - Subject age 
sex - Subject gender '0' - male, '1' - female 
test_time - Time since recruitment into the trial. The integer part is the number of days since recruitment. 
motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated 
total_UPDRS - Clinician's total UPDRS score, linearly interpolated (UPDRS is stands for Unified Parkison's Disease Rating Scale and is used to rate the severity of Parkinson's)
Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequency (fundamental frequency is the lowest frequency of a sound wave).
Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitude 
NHR,HNR - Two measures of ratio of noise to tonal components in the voice 
RPDE - A nonlinear dynamical complexity measure 
DFA - Signal fractal scaling exponent 
PPE - A nonlinear measure of fundamental frequency variation

This document will use decision tree methods (including boosting, bagging, and random forests) to predict total updrs score, sex, and age. We will then compare these results to those found with the methods used in Project 3. We will also look at unsupervised learning methods to explore more about the dataset.

## Predicting Parkinson's Severity
We used boosting and random forests to model and predict total updrs, a measure of Parkinson's severity.
### Boosting
```{r}
boost.parkinsons=gbm(total_updrs~.,data=df_tot_nums[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.parkinsons,plotit=FALSE)
```
The boosting model shows that age is the most significant predictor in the model. After that, dfa, tes_time, binary sex status, and hnr, as well a few other variables contribute more than 1%.

Next, we looked at the error from this model.
```{r}
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.parkinsons,newdata=df_tot_nums[-train,],n.trees=n.trees)
dim(predmat)

berr=with(df_tot_nums[-train,],apply( (predmat-total_updrs)^2,2,mean))
renderPlot({
  plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
  abline(h=min(berr),col="red")
})
```
The error with 10000 trees gets quite low, which is a significant improvement over the models found in the previous project.

### Random Forest
We also used a random forest model to predict total updrs.
```{r}
rf.total=randomForest(total_updrs~.,data=df_tot_nums,subset=train)
rf.total
```
This shows that the total variance explained is 80%.

We looked at the testing error and out-of-bag error estimate for this model for mtry of 1 through 19, the total number of predictors. Mtry of 19 is the same as bagging.
```{r}
dim(df_tot_nums)
oob.err=double(19)
test.err=double(19)
for(mtry in 1:19){
  fit=randomForest(total_updrs~.,data=df_tot_nums,subset=train,ntree=400)
  oob.err[mtry]=fit$mse[400]
  pred=predict(fit,df_tot_nums[-train,])
  test.err[mtry]=with(df_tot_nums[-train,],mean((total_updrs-pred)^2))
  cat(mtry," ")
}
renderPlot({
  matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
  legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
})
```
Although tihs error seems to be jumping around quite a bit, it is important to note taht the y axis is only spaning 0.02. The dips in the error may be due to including correlated variables, of which there are a significant number. Boosting does a better job in this regard than random forests.

### Comparison to Subset Selection for Parkinson's Severity
Boosting and random forests do a much better job of explaining variance in the total updrs, which is the main purpose of this dataset. Boosting also has good prediction accuracy in regards to this outcome.

K means clustering between total updrs and age (the most significant predictor in the boostng model) may illuminate why linear models didn't do such a good job.

```{r}
x = df%>%dplyr::select(age,total_updrs)
km.out=kmeans(x,6)
km.out
par(mfrow = c(1,2))
renderPlot(plot(x,col=km.out$cluster,cex=2,main = "K means clustering", pch=1,lwd=2))
renderPlot(plot(x,col=df$subject,cex=2,main = "Actual subject",pch=1,lwd=2))
```

K means clustering with 6 clusters shows that the lowest total updrs scores are associated with lower ages, while the highest scores are associated with the higher ages. However, there is a lot of vertical overlap in the clusters of the middle ages, which would make it more difficult for a linear model to deal with.

Find relevant insights here:
[Boosting for total updrs](https://data.world/tarrantrl/f-17-eda-project-4/insights/2e571834-aa7c-4ba9-887c-5239895d4692)
[Updated boosting for total updrs](https://data.world/tarrantrl/f-17-eda-project-4/insights/4635b284-3125-4c14-85f4-1a06a2b4afa5)
[Random forest for total updrs](https://data.world/tarrantrl/f-17-eda-project-4/insights/939f6c2e-6402-42bb-980a-7debf8507a62)
[K means for total updrs and age](https://data.world/tarrantrl/f-17-eda-project-4/insights/7302aa49-2762-441e-a0fe-949fa2e88ade)



## Predicting Sex
We used boosting and random forests to predict sex, since our data predicted sex well in the previous project. We also used linear and nonlinear support vector machines to classify data by sex.

### Boosting
First, we used boosting to predict sex.
```{r}
boost.df_sex=gbm(sex2~.,data=df_sex[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.df_sex)
```
Boosting identifies jitter abs and age as the most important predictors.

We then looked at the prediction error using boosting.
```{r}
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.df_sex,newdata=df_sex[-train,],n.trees=n.trees)
berr=with(df_sex[-train,],apply( (predmat-sex2)^2,2,mean))
renderPlot(plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error"))
```
The test error got very low, below 0.02, with the boosting model.

Find relevant insights here:
[Boosting for sex](https://data.world/tarrantrl/f-17-eda-project-4/insights/6ce8d905-8851-46a0-9ac9-ca2a96ec88bc)

### Random Forest
We also used random forests to predict sex.
```{r}
rf.sex=randomForest(as.factor(sex2)~.-sex,data=df_sex,subset=train)
rf.sex
```
The confusion matrix shows that this model does an overwhelmingly good job with mtry of 4.

We looked at the out of bag and tesing error for mtry of 1 through 20, which 20 variables used at each split representing bagging.
```{r}
oob.err=double(20)
test.err=double(20)
for(mtry in 1:20){
  fit=randomForest(sex2~.-sex,data=df_sex,subset=train,mtry=mtry,ntree=400)
  oob.err[mtry]=fit$mse[400]
  pred=predict(fit,df_sex[-train,])
  test.err[mtry]=with(df_sex[-train,],mean((sex2-pred)^2))
  cat(mtry," ")
}
renderPlot({
  matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
  legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
})
```
Since the error reaches a minimum at mtry=20, this shows that bagging actually does a better job than random forests.

Find relevant insights here:
[Decision tree for sex](https://data.world/tarrantrl/f-17-eda-project-4/insights/b23e858d-45d1-4c2e-9022-ae4046360e50)
[Random forest for sex](https://data.world/tarrantrl/f-17-eda-project-4/insights/a16305c3-ebf6-4d66-b1d7-1bb20731d641)
[Updated random forests for age and sex](https://data.world/tarrantrl/f-17-eda-project-4/insights/ba5f6283-21c5-49ce-9d36-c90d260b6299)

### Comparison to KNN
The prediction accuracy of K nearest neighbors, which was the best model in our previous project, was 0.94. Here, the error of boosting is less than 0.02, corresponding to a prediction accuracy of 0.98. Both of these models do well, but boosting wins out by a small margin. Bagging, with a test error below 0.06, also does better than KNN. This affirms the ability of both random forests and boosting to improve the prediction accuracy of decision trees to be a powerful model.

### Comparison to Lasso
In our last project, we used lasso to analyze the data and find the best predictors for predicting sex. We found that the 14 predictors with the highest coefficients were age, test_time, motor_updrs, total_updrs, jitter, jitter_abs, jitter_rap, shimmer_apq3, shimmer_dda, nhr, hnr, rpde, dfa, and ppe. In our boosting analysis, we found the top 14 predictors for sex with the highest relative influence in descending order were jitter_abs, age, jitter_ddp, motor_updrs, nhr, jitter_rap, dfa, jitter, hnr, total_updrs, shimmer_apq11, test_time, shimmer_apq5, and rpde. This boosting analysis didn't include shimmer_apq3, shimmer_dda, and ppe, choosing jitter_ddp, shimmer_apq11, and shimmer_apq5 instead. On the whole, however, these two methods chose similar predictors, confirming the overall importance of those 11 common predictors.

### Linear SVM
After using boosting to decide which predictors influence sex the most, we decided to choose the plot of jitter_abs vs dfa to classify by sex using SVM. We first created the model:
```{r}
x=subset(df2, select = c(dfa, jitter_abs))
x=matrix(unlist(x), ncol = 2)
y=df2$sex2
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,type="nu-classification",kernel="linear",cost=10,scale=FALSE)
print(svmfit)
#plot(svmfit,dat)
```
Then we created the plot of jitter_abs vs dfa and added the decision boundary with margins and the support points.
```{r}
make.grid=function(x,n=150){
  grange=apply(x,2,range)
  x1=seq(from=grange[1,1],to=grange[2,1],length=n)
  x2=seq(from=grange[1,2],to=grange[2,2],length=n)
  expand.grid(X1=x1,X2=x2)
}
xgrid=make.grid(x)
ygrid=predict(svmfit,xgrid)

beta=drop(t(svmfit$coefs)%*%x[svmfit$index,])
beta0=svmfit$rho
renderPlot({
  plot(xgrid,col=c("yellow","blue")[as.numeric(ygrid)],pch=20,cex=.2)
  points(x,col=y+3,pch=19)
  points(x[svmfit$index,],pch=5,cex=2)
  abline(beta0/beta[2],-beta[1]/beta[2])
  abline((beta0-1)/beta[2],-beta[1]/beta[2],lty=2)
  abline((beta0+1)/beta[2],-beta[1]/beta[2],lty=2)
})
```
The linear SVM seemed to split the male and female points at an appropriate decision boundary. A large group of female points are to the left of the boundary and a large amount of male points are to the right. However, the margins are very small due to the data being so close together. Many of the male and female points overlap, so a linear SVM was not a good choice for this data. 

### Nonlinear SVM
Next we tried classifying by sex for the same plot of jitter_abs vs dfa, except this time we used a nonlinear type SVM with a radial kernel.
```{r}
x=subset(df2, select = c(dfa, jitter_abs))
x=matrix(unlist(x), ncol = 2)
y=df2$sex2
nlsvmfit=svm(factor(y)~.,data=dat,type="nu-classification",scale=TRUE,kernel="radial",cost=10)
#plot(nlsvmfit, dat)
```
Then we plotted the new SVM nonlinear decision boundary:
```{r}
x1=seq(.5, .85, by=0.35/149.0)
x2=seq(0, .0004, by=0.0004/149.0)
xgrid=expand.grid(X1=x1,X2=x2)
ygrid=predict(nlsvmfit,xgrid)
func=predict(nlsvmfit,xgrid,decision.values=TRUE)
func=attributes(func)$decision
renderPlot({
  plot(xgrid,col=as.numeric(ygrid),pch=20,cex=.2)
  points(x,col=y+1,pch=19)
  contour(x1,x2,matrix(func,150,150),level=0,add=TRUE)
})
```
This decision boundary is able to classify better than the linear one due to its ability to curve around the center to capture male points in the center of the boundary and female points in the outside red area of the boundary. The abnormal shape also juts out in places to capture points that a circular shape might not have included. Overall, this is probably close to the best decision boundary that SVM can create on this data. No shape would be able to correctlly classify all of the overlapping points towards the center.

Find relevant insights here:
[Linear SVM for jitter abs and dfa](https://data.world/tarrantrl/f-17-eda-project-4/insights/fbe1f5d3-4b76-421c-8da7-8fd9b9b3bd65)
[Non linear SVM for jitter abs and dfa](https://data.world/tarrantrl/f-17-eda-project-4/insights/ced4b656-b6ba-4c34-ba96-39ff79856e9c)


## Predicting Age
Although we didn't look into predicting age as much in the previous project, we were able to explore it more in this project using boosting and random forests.
### Boosting
First, we made a boosting model to predict age as a classification problem, dividing age into younger than or equal to 65 (designated 1) and older 65 (designated 0).
```{r}
boost.age=gbm(age2~.-age,data=df_age[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.age,plotit=FALSE)
```
Total and motor updrs both played a significant role in predicting sex, which makes sense because Parkinson's worsens with age.

We then looked at the testing error for the boosting model.
```{r}
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.age,newdata=df_age[-train,],n.trees=n.trees)

berr=with(df_age[-train,],apply( (predmat-age2)^2,2,mean))
renderPlot({}
  plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error"))
  abline(h=min(test.err),col="red")
})
```
The error continues to decrease as the model uses more and more trees and is less than 0.06, demonstrating the predictive strength of this model.

### Random Forests
Next, we used a random forest model to classify age.
```{r}
rf.age=randomForest(as.factor(age2)~.-age,data=df_age,subset=train)
rf.age
```
Less than 10% of the training data is misclassified, which is pretty good.
We then looked at the out of bag and testing error, using mtry of 1 to 20.
```{r}
oob.err=double(20)
test.err=double(20)
for(mtry in 1:20){
  fit=randomForest(age2~.-age,data=df_age,subset=train,mtry=mtry,ntree=400)
  oob.err[mtry]=fit$mse[400]
  pred=predict(fit,df_age[-train,])
  test.err[mtry]=with(df_age[-train,],mean((age2-pred)^2))
  cat(mtry," ")
}
renderPlot({
  matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
  legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
})
```
As with predicting sex using random forests, this graph shows that regular bagging actually does a better job than the random forest models. Again, this model has error less than 0.06 like boosting. The out of bag error closely predicts the testing error as well. Both of these models predict age classification with great accuracy.


For relevent insights, see:
[Decision tree predicting age](https://data.world/tarrantrl/f-17-eda-project-4/insights/3f7ef916-3e2b-4cdc-93d1-e53ab8aa7c43)
[Updated decision tree predicting age](https://data.world/tarrantrl/f-17-eda-project-4/insights/2b7c0f4e-f6f5-4571-8ed7-6cb160813a22)
[Predicting age with boosting](https://data.world/tarrantrl/f-17-eda-project-4/insights/4142e8c0-817c-4332-a12e-356bfdbe8990)
[Random forest for age](https://data.world/tarrantrl/f-17-eda-project-4/insights/319cb9ba-854d-4051-a405-7b9899767764)
[Boosting for age](https://data.world/tarrantrl/f-17-eda-project-4/insights/20ec2b27-1732-4702-b923-a268529fa29a)
[Updated random forests for age and sex](https://data.world/tarrantrl/f-17-eda-project-4/insights/ba5f6283-21c5-49ce-9d36-c90d260b6299)



## Unsupervised Learning
In addition to exploring predictive methods using decision trees, we also used unsupervised learning methods to discover more about our data.

### K-means Clustering
Using K means clustering, we were able to learn about the scope of the study. There were 42 subjects in the study, so we used 42 centers to cluster data using age and total updrs as factors. We then compared this to the real subject classification.
```{r}
x = df%>%dplyr::select(age, total_updrs)
km.out=kmeans(x,42)
km.out
par(mfrow = c(1, 2))
renderPlot(plot(x,col=km.out$cluster,cex=2,main = "K means clustering", pch=1,lwd=2))
renderPlot(plot(x,col=df$subject,cex=2,main = "Actual subject",pch=1,lwd=2))
```
Clustering was able to closely mimic true subject classification. One thing this visualization brings out is the fact that age does not change over the course of the study for each subject. This shows that the study was not longitudinal. A longitudinal study may yield more informative data because total updrs score would likely change significantly more over a course of years than over a course of months.

As mentioned earlier, using fewer clusters with age does shows some meaningful trends in regards to total updrs. See the total updrs section above for more information.

### Hierchical Clustering
We also used hierarchical clustering to look at the clustering of the data by subject.
```{r}
hc.complete=hclust(dist(x),method="complete")
hc.single=hclust(dist(x),method="single")
hc.average=hclust(dist(x),method="average")
par(mfrow = c(3, 1))
renderPlot(plot(hc.complete))
renderPlot(plot(hc.single))
renderPlot(plot(hc.average))
```
Cutting the trees at 42 (to represent the number of real subjects) and looking at the confusing matrix shows how well this model was able to cluser by subject.
```{r}
hc.cut=cutree(hc.complete,42)
table(hc.cut,df$subject)
table(hc.cut,km.out$cluster)
```
Since the matrix is mostly zeros, this shows that hierarchical clustering was able to cluster well in regards to true subject. The results are similar to those found with k means.

The fact that the data can ultimately be traced back pretty easily to sujbect may have an effect on our analyses. Although we removed subject from our other models, a lack of variation within the data points for each subject may be why we had some trouble predicting total updrs in the last project. For example, age does not predict updrs score for one subject because that subject's age did not change. Perhaps it would be beneficial to take into accound test time and create a floating point age that takes into account the passage of time within each subject's data.

Find relevant insights here:
[K means for total updrs and age](https://data.world/tarrantrl/f-17-eda-project-4/insights/7302aa49-2762-441e-a0fe-949fa2e88ade)
[Hierarchical clustering](https://data.world/tarrantrl/f-17-eda-project-4/insights/dd034ffe-c196-43cc-a219-fa559ffd2bf1)
[K means clustering for total updrs and subject](https://data.world/tarrantrl/f-17-eda-project-4/insights/5c848361-bac7-490c-b4b9-ba13b310e545)


## Findings

Overall, decision trees and related methods had greater predictive power and accuracy than the models we used in Project 3. Particularly for total updrs, boosting and random forests made prediction feasible when it did not seem possible with linear models found in subset selection. This is extremely encouraging because total updrs is the most medically relevant outcome to predict. Additionally, due to the interpretability of decision trees, simpler decision trees could be of use to doctors in diagnosing the early disease.

Unsupervised learning methods using clustering demonstrated some characteristics about our data that help to explain why linear models and simpler classification schemes did not always fair well. Due to a lack of variation in the data, particularly regarding each subject, there is a lot of overlap between data points that makes trends obscure. K means clustering helped to visualize some of these trends in a different way, and boosting and bagging were able to predict these trends as well.


## Miscellaneous Insights
[PCA first attempt](https://data.world/tarrantrl/f-17-eda-project-4/insights/2c86b2d3-9787-401c-91f5-9533d4cbaac6)
[Boosting for status](https://data.world/tarrantrl/f-17-eda-project-4/insights/ddd993c3-1fb8-441c-a3ec-3d543e566150)
[Random Forests for status](https://data.world/tarrantrl/f-17-eda-project-4/insights/4433b10d-c137-488d-92e4-ffcc3b71a0fc)
[Decision Tree Predicting Status](https://data.world/tarrantrl/f-17-eda-project-4/insights/a405b6a8-0df4-40b1-9ff6-4051102ff011)
